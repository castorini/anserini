conditions:
  - name: bm25-doc
    display: "BM25 doc (k1=0.9, b=0.4)"
    display_html: "BM25 doc (<i>k<sub><small>1</small></sub></i>=0.9, <i>b</i>=0.4)"
    display_row: ""
    command: java -cp $fatjar --add-modules jdk.incubator.vector io.anserini.search.SearchCollection -threads $threads -index msmarco-v2.1-doc -topics $topics -output $output -hits 1000 -bm25
    topics:
      - topic_key: msmarco-v2-doc.dev
        eval_key: msmarco-v2.1-doc.dev
        expected_scores:
          MRR@100: 0.1654
        metric_definitions:
          MRR@100: "-c -M 100 -m recip_rank"
      - topic_key: msmarco-v2-doc.dev2
        eval_key: msmarco-v2.1-doc.dev2
        expected_scores:
          MRR@100: 0.1732
        metric_definitions:
          MRR@100: "-c -M 100 -m recip_rank"
      - topic_key: dl21-doc
        eval_key: dl21-doc-msmarco-v2.1
        expected_scores:
          MAP@100: 0.2281
          MRR@100: 0.8466
          nDCG@10: 0.5183
          R@100: 0.3502
          R@1K: 0.6915
        metric_definitions:
          MAP@100: "-c -M 100 -m map"
          MRR@100: "-c -M 100 -m recip_rank"
          nDCG@10: "-c -m ndcg_cut.10"
          R@100: "-c -m recall.100"
          R@1K: "-c -m recall.1000"
      - topic_key: dl22-doc
        eval_key: dl22-doc-msmarco-v2.1
        expected_scores:
          MAP@100: 0.0841
          MRR@100: 0.6623
          nDCG@10: 0.2991
          R@100: 0.1866
          R@1K: 0.4254
        metric_definitions:
          MAP@100: "-c -M 100 -m map"
          MRR@100: "-c -M 100 -m recip_rank"
          nDCG@10: "-c -m ndcg_cut.10"
          R@100: "-c -m recall.100"
          R@1K: "-c -m recall.1000"
      - topic_key: dl23-doc
        eval_key: dl23-doc-msmarco-v2.1
        expected_scores:
          MAP@100: 0.1089
          MRR@100: 0.5783
          nDCG@10: 0.2914
          R@100: 0.2604
          R@1K: 0.5383
        metric_definitions:
          MAP@100: "-c -M 100 -m map"
          MRR@100: "-c -M 100 -m recip_rank"
          nDCG@10: "-c -m ndcg_cut.10"
          R@100: "-c -m recall.100"
          R@1K: "-c -m recall.1000"
      - topic_key: rag24.raggy-dev
        eval_key: rag24.raggy-dev
        expected_scores:
          MAP@100: 0.1251
          MRR@100: 0.7060
          nDCG@10: 0.3631
          R@100: 0.2433
          R@1K: 0.5317
        metric_definitions:
          MAP@100: "-c -M 100 -m map"
          MRR@100: "-c -M 100 -m recip_rank"
          nDCG@10: "-c -m ndcg_cut.10"
          R@100: "-c -m recall.100"
          R@1K: "-c -m recall.1000"
  - name: bm25-segmented-doc
    display: "BM25 segmented doc (k1=0.9, b=0.4)"
    display_html: "BM25 segmented doc (<i>k<sub><small>1</small></sub></i>=0.9, <i>b</i>=0.4)"
    display_row: ""
    command: java -cp $fatjar --add-modules jdk.incubator.vector io.anserini.search.SearchCollection -threads $threads -index msmarco-v2.1-doc-segmented -topics $topics -output $output -hits 10000 -bm25 -selectMaxPassage -selectMaxPassage.delimiter \# -selectMaxPassage.hits 1000
    topics:
      - topic_key: msmarco-v2-doc.dev
        eval_key: msmarco-v2.1-doc.dev
        expected_scores:
          MRR@100: 0.1973
        metric_definitions:
          MRR@100: "-c -M 100 -m recip_rank"
      - topic_key: msmarco-v2-doc.dev2
        eval_key: msmarco-v2.1-doc.dev2
        expected_scores:
          MRR@100: 0.2000
        metric_definitions:
          MRR@100: "-c -M 100 -m recip_rank"
      - topic_key: dl21-doc
        eval_key: dl21-doc-msmarco-v2.1
        expected_scores:
          MAP@100: 0.2609
          MRR@100: 0.9026
          nDCG@10: 0.5778
          R@100: 0.3811
          R@1K: 0.7115
        metric_definitions:
          MAP@100: "-c -M 100 -m map"
          MRR@100: "-c -M 100 -m recip_rank"
          nDCG@10: "-c -m ndcg_cut.10"
          R@100: "-c -m recall.100"
          R@1K: "-c -m recall.1000"
      - topic_key: dl22-doc
        eval_key: dl22-doc-msmarco-v2.1
        expected_scores:
          MAP@100: 0.1079
          MRR@100: 0.7213
          nDCG@10: 0.3576
          R@100: 0.2330
          R@1K: 0.4790
        metric_definitions:
          MAP@100: "-c -M 100 -m map"
          MRR@100: "-c -M 100 -m recip_rank"
          nDCG@10: "-c -m ndcg_cut.10"
          R@100: "-c -m recall.100"
          R@1K: "-c -m recall.1000"
      - topic_key: dl23-doc
        eval_key: dl23-doc-msmarco-v2.1
        expected_scores:
          MAP@100: 0.1391
          MRR@100: 0.6519
          nDCG@10: 0.3356
          R@100: 0.3049
          R@1K: 0.5852
        metric_definitions:
          MAP@100: "-c -M 100 -m map"
          MRR@100: "-c -M 100 -m recip_rank"
          nDCG@10: "-c -m ndcg_cut.10"
          R@100: "-c -m recall.100"
          R@1K: "-c -m recall.1000"
      - topic_key: rag24.raggy-dev
        eval_key: rag24.raggy-dev
        expected_scores:
          MAP@100: 0.1561
          MRR@100: 0.7465
          nDCG@10: 0.4227
          R@100: 0.2807
          R@1K: 0.5745
        metric_definitions:
          MAP@100: "-c -M 100 -m map"
          MRR@100: "-c -M 100 -m recip_rank"
          nDCG@10: "-c -m ndcg_cut.10"
          R@100: "-c -m recall.100"
          R@1K: "-c -m recall.1000"
